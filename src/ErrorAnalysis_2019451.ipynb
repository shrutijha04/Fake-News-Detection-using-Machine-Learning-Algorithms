{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ErrorAnalysis_LR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACqgX6zRefHa"
      },
      "outputs": [],
      "source": [
        "#1. class distribution of test set? - is accuracy even a good metric? - balanced classes - 0.51 fake, 0.49 real\n",
        "#2. is auc good if class distribution is inequal?\n",
        "\n",
        "#dataset inc[-no author-], k=10\n",
        "\"\"\"\n",
        "Comparing the LR model on the test sets\n",
        "\n",
        "Evaluation Metrics:\n",
        "Accuracy:  0.621031746031746\n",
        "Precision:  0.6624489795918367\n",
        "Recall:  0.5997782705099778\n",
        "f1-score:  0.62955779674166\n",
        "\"\"\"\n",
        " \n",
        "#count2vect\n",
        "\"\"\"\n",
        "Accuracy:  0.6421153846153846\n",
        "Precision:  0.6931993817619784\n",
        "Recall:  0.6270534778049633\n",
        "f1-score:  0.658469443934667\n",
        "\"\"\"\n",
        "\n",
        "#1. add author, dec #features - gives better accuracy with add author+1000 : [worse with l2 and c=1e-4]\n",
        "\"\"\"\n",
        "Evaluation Metrics:\n",
        "Accuracy:  0.6078345070422535\n",
        "Precision:  0.6401225114854517\n",
        "Recall:  0.5379665379665379\n",
        "f1-score:  0.5846153846153846\n",
        "\"\"\"\n",
        "# but without penalty: \n",
        "\"\"\"\n",
        "Evaluation Metrics:\n",
        "Accuracy:  0.6080545774647887\n",
        "Precision:  0.6401630988786952\n",
        "Recall:  0.5388245388245388\n",
        "f1-score:  0.5851385977172141\n",
        "\"\"\"\n",
        "\n",
        "#2. normalize tfidf output with l2\n",
        "\"\"\"\n",
        "Evaluation Metrics:\n",
        "Accuracy:  0.6078345070422535\n",
        "Precision:  0.6401225114854517\n",
        "Recall:  0.5379665379665379\n",
        "f1-score:  0.5846153846153846\n",
        "\"\"\"\n",
        "\n",
        "#3. shuffle=True in stratifiedkfold\n",
        "\"\"\"\n",
        "Evaluation Metrics:\n",
        "Accuracy:  0.6078345070422535\n",
        "Precision:  0.6401225114854517\n",
        "Recall:  0.5379665379665379\n",
        "f1-score:  0.5846153846153846\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 1E8OTtNK_UNSAdmkg3OuB0k2FsKKF9QpY\n",
        "! gdown --id 1-pm6_kvT9CBrYER40uIkRiG0KMlHnH7L\n",
        "! gdown --id 1oiVQignVg1wvE1LXKFvOLHPl0P8GNSDp"
      ],
      "metadata": {
        "id": "EJoYcT_xiCvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1ahCrVIriDpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"train.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "submit_data = pd.read_csv(\"submit.csv\")\n",
        "test_data = test_data.join(submit_data[\"label\"])"
      ],
      "metadata": {
        "id": "B1cee4ksiD1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"author\"].fillna(\"-NO AUTHOR-\", inplace = True)\n",
        "test_data[\"author\"].fillna(\"-NO AUTHOR-\", inplace = True)"
      ],
      "metadata": {
        "id": "BHqlMzyHxuto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing null values\n",
        "train_data.dropna(inplace=True)\n",
        "train_data.drop(train_data.loc[train_data['text']==\" \"].index, inplace=True)\n",
        "train_data.drop(train_data.loc[train_data['text']==\"  \"].index, inplace=True)\n",
        "train_data.drop(train_data.loc[train_data['text']==\"\\n\"].index, inplace=True)\n",
        "\n",
        "# Resetting index\n",
        "train_data.reset_index(inplace=True)\n",
        "train_data= train_data.apply(lambda x: x.astype(str).str.lower())\n",
        "train_data = train_data.drop(columns=[\"id\", \"index\"])"
      ],
      "metadata": {
        "id": "OJe7-z0ZiD5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing null values\n",
        "test_data.dropna(inplace=True)\n",
        "test_data.drop(test_data.loc[test_data['text']==\" \"].index, inplace=True)\n",
        "test_data.drop(test_data.loc[test_data['text']==\"  \"].index, inplace=True)\n",
        "test_data.drop(test_data.loc[test_data['text']==\"\\n\"].index, inplace=True)\n",
        "\n",
        "# Resetting index\n",
        "test_data.reset_index(inplace=True)\n",
        "\n",
        "test_data= test_data.apply(lambda x: x.astype(str).str.lower())\n",
        "test_data = test_data.drop(columns=[\"id\",\"index\"])"
      ],
      "metadata": {
        "id": "Bf5bt50LiEAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.describe()"
      ],
      "metadata": {
        "id": "fXNmUr1tjcN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "_i-PVhVHiECJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 1pGkEyDelD7Lp7yhFML9Dt1oo-91Mqf9H\n",
        "! gdown --id 1DYVzeYjjTTeHtazHfKD9FTx57h-77bkC"
      ],
      "metadata": {
        "id": "GLZt3QqUiTDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_df = pd.read_csv(\"pre_train.csv\")\n",
        "transformed_df_test = pd.read_csv(\"pre_test.csv\")\n",
        "X_test = transformed_df_test.values\n",
        "y_test = test_data[\"label\"].values "
      ],
      "metadata": {
        "id": "o0y7G6TDiURM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stratified Kfold (k=5) split for training data\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
        "\n",
        "X = transformed_df.values\n",
        "y = train_data[\"label\"].values \n",
        "\n",
        "X_train=[]\n",
        "X_val=[]\n",
        "y_train=[]\n",
        "y_val=[]\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "  X_train.append(X[train_index])\n",
        "  X_val.append(X[test_index]) \n",
        "  y_train.append(y[train_index])\n",
        "  y_val.append(y[test_index])\n"
      ],
      "metadata": {
        "id": "QgpJah1aiYBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "add author in preprocessing"
      ],
      "metadata": {
        "id": "S62ZGJ2Flsjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfLNhpXQlur0",
        "outputId": "b55d949e-a864-4d54-d905-fc01ecf983ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#append author to front of text\n",
        "#train data"
      ],
      "metadata": {
        "id": "-v9QQHyKl52L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['author', 'text']\n",
        "train_data1 = train_data\n",
        "train_data1['combined'] = train_data1[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
      ],
      "metadata": {
        "id": "IlsngRDRl814"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data1 = train_data1.drop(columns=[\"author\",\"text\"])"
      ],
      "metadata": {
        "id": "pN9eizlkmiua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data1.rename(columns = {'combined':'text'}, inplace = True)"
      ],
      "metadata": {
        "id": "P4qUMgZ0mw3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_set = set(stopwords.words('english'))\n",
        "\n",
        "sw_removed = []\n",
        "\n",
        "for i in range(len(train_data1)):\n",
        "    review = re.sub('[^a-zA-Z]',' ',train_data1['text'][i])\n",
        "    #not on title?\n",
        "    review = review.split()\n",
        "    review = [word for word in review if not word in stop_words_set]\n",
        "    statements = ' '.join(review)\n",
        "    sw_removed.append(statements)\n"
      ],
      "metadata": {
        "id": "P7dhA5_cl3MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "stemmed = []\n",
        "\n",
        "print(len(sw_removed))\n",
        "\n",
        "for i in range(len(sw_removed)):\n",
        "  sw_removed_1 = sw_removed[i].split()\n",
        "  stem = [ps.stem(word) for word in sw_removed_1]\n",
        "  st = ' '.join(stem)\n",
        "  stemmed.append(st)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeE_OxRNnEQa",
        "outputId": "367016d0-c978-4df1-b164-a4e612f74344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_arr = np.array(stemmed)\n",
        "#preprocess_df = pd.DataFrame(preprocess_arr)"
      ],
      "metadata": {
        "id": "K9gLoUCTnGlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=100) #3000\n",
        "\n",
        "train_input = vectorizer.fit_transform(preprocess_arr).toarray()\n",
        "transformed_df = pd.DataFrame(data=train_input, columns=vectorizer.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D8JfyamnHJQ",
        "outputId": "358348df-adea-408e-a32b-ea4a1c7cf2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set"
      ],
      "metadata": {
        "id": "1CvY6V9dnItk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['author', 'text']\n",
        "test_data1 = test_data\n",
        "test_data1['combined'] = test_data1[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "test_data1 = test_data1.drop(columns=[\"author\",\"text\"])\n",
        "test_data1.rename(columns = {'combined':'text'}, inplace = True)"
      ],
      "metadata": {
        "id": "eJrt5fR_nJpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_set = set(stopwords.words('english'))\n",
        "\n",
        "sw_removed = []\n",
        "\n",
        "for i in range(len(test_data1)):\n",
        "    review = re.sub('[^a-zA-Z0-9]',' ',test_data1['text'][i])\n",
        "    review = review.split()\n",
        "    review = [word for word in review if not word in stop_words_set]\n",
        "    statements = ' '.join(review)\n",
        "    sw_removed.append(statements)\n"
      ],
      "metadata": {
        "id": "Yn-d4oTjnZNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "stemmed = []\n",
        "\n",
        "print(len(sw_removed))\n",
        "\n",
        "for i in range(len(sw_removed)):\n",
        "  sw_removed_1 = sw_removed[i].split()\n",
        "  stem = [ps.stem(word) for word in sw_removed_1]\n",
        "  st = ' '.join(stem)\n",
        "  stemmed.append(st)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMXxSoIhncXM",
        "outputId": "81bc1b82-67e7-49a2-c509-b58e0e943383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_arr_test = np.array(stemmed)\n",
        "test_input = vectorizer.transform(preprocess_arr_test).toarray()\n",
        "transformed_df_test = pd.DataFrame(data=test_input, columns=vectorizer.get_feature_names())\n",
        "X_test = transformed_df_test.values\n",
        "y_test = test_data1[\"label\"].values "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9ofOjcQne8H",
        "outputId": "96dd34e5-f6a2-4148-a6be-28efd420c7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizing using minmax scalar\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "Whlh5RQJvBQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(transformed_df)\n",
        "scaler.transform(transformed_df)\n",
        "scaler.transform(transformed_df_test)"
      ],
      "metadata": {
        "id": "4sGskBh6vJyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = transformed_df_test.values\n",
        "y_test = test_data1[\"label\"].values "
      ],
      "metadata": {
        "id": "VCpiPgj8vetz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stratified Kfold (k=5) split for training data\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
        "\n",
        "X = transformed_df.values\n",
        "y = train_data1[\"label\"].values \n",
        "\n",
        "\"\"\"X_train=[]\n",
        "X_val=[]\n",
        "y_train=[]\n",
        "y_val=[]\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "  X_train.append(X[train_index])\n",
        "  X_val.append(X[test_index]) \n",
        "  y_train.append(y[train_index])\n",
        "  y_val.append(y[test_index])\"\"\"\n"
      ],
      "metadata": {
        "id": "YaorKIbSqJkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "485628a5-7592-4566-e0e3-54e20f2b1802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'X_train=[]\\nX_val=[]\\ny_train=[]\\ny_val=[]\\n\\nfor train_index, test_index in skf.split(X, y):\\n  X_train.append(X[train_index])\\n  X_val.append(X[test_index]) \\n  y_train.append(y[train_index])\\n  y_val.append(y[test_index])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "wMEutmQWsAgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr_1 = LogisticRegression(random_state=0, C=838, fit_intercept=True, max_iter=760, penalty='l2', tol=0.0003)  "
      ],
      "metadata": {
        "id": "XzrzS-IwsB_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr_1.fit(X, y.astype('int'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOp7N41csDko",
        "outputId": "3d9c7563-df6d-4339-f086-dfdbc70e1806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=838, max_iter=760, random_state=0, tol=0.0003)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "W4lpMt0Mse1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_lr_1.predict(X_test)\n",
        "\n",
        "print('Comparing the LR model on the test sets')\n",
        "#model 1\n",
        "print('\\nEvaluation Metrics:')\n",
        "print(\"Accuracy: \", accuracy_score( y_test.astype('int'), y_pred))\n",
        "print(\"Precision: \", precision_score( y_test.astype('int'), y_pred))\n",
        "print(\"Recall: \", recall_score( y_test.astype('int'), y_pred))\n",
        "print(\"f1-score: \", f1_score( y_test.astype('int'), y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzV-DuDfsNPI",
        "outputId": "3a4ebfb1-bd93-4641-8f48-90de56a4ec63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing the LR model on the test sets\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy:  0.6240079365079365\n",
            "Precision:  0.6666666666666666\n",
            "Recall:  0.5994087213599408\n",
            "f1-score:  0.6312512161899202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr_1 = LogisticRegression(random_state=0, C=1e-2, fit_intercept=True, max_iter=760, penalty='none', tol=0.0003)  "
      ],
      "metadata": {
        "id": "8wfGXVRbtJmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr_1.fit(X, y.astype('int'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN7rRWbftLsQ",
        "outputId": "5f36e45c-85e3-4228-d710-b02a5bc845d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.01, max_iter=760, penalty='none', random_state=0,\n",
              "                   tol=0.0003)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_lr_1.predict(X_test)\n",
        "\n",
        "print('Comparing the LR model on the test sets')\n",
        "#model 1\n",
        "print('\\nEvaluation Metrics:')\n",
        "print(\"Accuracy: \", accuracy_score( y_test.astype('int'), y_pred))\n",
        "print(\"Precision: \", precision_score( y_test.astype('int'), y_pred))\n",
        "print(\"Recall: \", recall_score( y_test.astype('int'), y_pred))\n",
        "print(\"f1-score: \", f1_score( y_test.astype('int'), y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icv6PSYItPvB",
        "outputId": "6ec6c01f-f13e-44cc-bb66-0691db7ccbf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing the LR model on the test sets\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy:  0.6080545774647887\n",
            "Precision:  0.6401630988786952\n",
            "Recall:  0.5388245388245388\n",
            "f1-score:  0.5851385977172141\n"
          ]
        }
      ]
    }
  ]
}